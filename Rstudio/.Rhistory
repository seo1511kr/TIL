# 기본형식이 아닌경우 format 옵션 필요
as.Date("02-26-2021", format='%m/%d/%y')
# 기본형식이 아닌경우 format 옵션 필요
as.Date("02-26-2021", format='%m/%d/%y')
# 기본형식이 아닌경우 format 옵션 필요
as.Date("02-26-2021", format='%m-%d-%y')
as.Date("02/26/2021", format='%m/%d/%y')
#
d<-as.Date('2021-02-26')
format(d,format='%m/%d/%y')
class(format(d,format='%m/%d/%y'))
today<-Sys.Date()
today
class(d)
format(d,format='%m/%d/%y')
class(format(d,format='%m/%d/%y'))
today<-Sys.Date()
today
format(today,format='%Y/%m/%d %A')
weekdays(as.Date('2021-02-27'))
weekdays(as.Date('2021/02/27'))
d<-as.Date('2021/02/27')
d-1
d+1:10
weekdays(d)
weekdays(d+1:10)
#날짜 데이터 생성 seq()함수 활용
s<-as.Date('2021-02-26')
e<-as.Date('2021-04-1')
seq(from=s,to=3,by=1)
s<-as.Date('2021-02-26')
e<-as.Date('2021-04-1')
seq(from=s,to=3,by=1)
seq(from=s,to=e,by=1)
seq(s,by=1,length.out=10)
seq(s,by=1,length.out=9)
seq(s,by=7,length.out=9)
seq(s,by='week',length.out=9)
seq(s,by='7 days',length.out=9)
seq(s,by='month',length.out=9)
seq(s,by='2 months',length.out=9)
seq(s,by='year',length.out=9)
seq(s,by='2 years',length.out=9)
seq(from=as.Date('2021-01-30'),by='month',length.out=5)
s<-as.Date('2021-02-26')
qrt<-seq(from=s,by='3 months', length.out=4)
qrt
months(qrt)
quraters(qrt)
quarters(qrt)
#파일 입출력
product<-data.frame()
product
product<-edit(product)
product
fix(product)
product
fix(product)
fix(product)
product
str(product)
product<-edit(product)
fix(product)
#edit(),fix(product)을 활용한 간단한 데이터 생성
product<-data.frame()
product
product<-edit(product)
product
#write.csv
write.csv(product,file='myproduct.csv')
product
write.csv(product,file='myproduct.csv',row.names=F)
product
#write.csv
write.csv(product,file='myproduct.csv')
write.csv(product,file='myproduct.csv',row.names=F)
product
p<-readClipboard()
p
read.table(file='Clipboard', sep='\t')
read.table(file='clipboard', sep='\t')
read.table(file='clipboard', sep='\t',header=TRUE)
#csv 파일에서 ctrl c로 복사한 데이터 가져오기
#[1] "id\tname\tprice"       "A001\tmouse\t10000"
#[3] "A002\tKeyboard\t20000" "A003\tUSB\t30000"
#처럼 출력됨 => read.table로 해결
p<-readClipboard()
p
read.table(file='clipboard', sep='\t',header=TRUE)
read.csv(product,file='data/product.csv')
product
read.csv('data/product.csv')
read.csv('data/product-with-no-header.csv')
read.csv('data/product.csv')
read.csv('data/product-with-no-header.csv')
p<-read.csv('data/product.csv')
str(p)
p<-read.csv('data/product.csv',stringsAsFactors = T)
str(p)
p<-read.csv('data/product.csv', as.is = T)
str(p)
p<-read.table('data/product.txt',header=T)
p
p<-read.table('data/product.txt')
p
str(p)
p<-read.table('data/product.txt',header=T)
p
str(p)
read.table('data/product-colon.txt')
read.table('data/product-colon.txt')
read.table('data/product-colon.txt',sep=':',header=T)
#누락된 데이터
read.table('data/product-missing.txt',sep=':',header=T)
read.table('data/product-missing.txt',sep=':',header=T,na.strings='.')
read.table('data/product-missing.txt',sep=':',header=T,na.strings='.')
#누락된 데이터
read.table('data/product-missing.txt',sep=':',header=T)
read.table('data/product-missing.txt',header=T,na.strings='.')
#누락된 데이터
read.table('data/product-missing.txt',header=T)
read.table('data/product-missing.txt',header=T,na.strings='.')
read.table('data/product-missing.txt',header=T,na.strings='누락락')
read.table('data/product-missing.txt',header=T,na.strings='누누락')
read.table('data/product-missing.txt',header=T,na.strings='누락')
read.table('data/product-missing.txt',header=T,na.strings=c('누락','몰라'))
read.table('data/product-comment.txt',header=T)
read.table('data/brand-eval.csv',header=T)
read.table('data/brand-eval.csv',header=T,sep='.')
read.table('data/brand-eval.csv',header=T,sep=',')
# csv를 read.table로 불러올 때 sep=','사용해야함
read.table('data/brand-eval.csv',header=T)
read.table('data/brand-eval.csv',header=T,sep=',',row.names = 'id')
read.table('data/brand-eval.csv',header=T,sep=',')
str(brand.eval)
brand.eval<-read.table('data/brand-eval.csv',header=T,sep=',',row.names = 'id')
str(brand.eval)
brand.eval<-read.table('data/brand-eval.csv',header=T,sep=',',row.names = 'id')
str(brand.eval)
brand.eval
brand.eval<-read.table('data/brand-eval.csv',header=T,sep=',',row.names = 'id',colClasses = c('character','character','numeric','numeric','numeric'))
brand.eval
#xlsx(엑셀)파일 열기
install.packages('openxlsx')
library(openxlsx)
read.xlsx('product.xlsx',sheet=1)
read.xlsx('data/product.xlsx',sheet=1)
# https://archive.ics.uci.edu/ml/datasets.php(캘리포니아 오픈 데이터)
#local에서 말고 직접 url로 데이터 받아서 불러오기
url<-"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data"
iris.uci<-read.csv(url,header=F)
iris.uci
#local에 저장하기
download.file(url=url,destfile = 'data/myIris.csv')
url<-"http://seanlahman.com/files/database/baseballdatabank-master_2016-03-02.zip"
local.copy<-'baseball.zip'
download.file(url,local.copy)
unzip(zipfile=local.copy,'baseballdatabank-master/core/Salaries.csv')
bs<-read.csv(unzip(zipfile=local.copy,'baseballdatabank-master/core/Salaries.csv'))
bs<-read.csv(unzip(zipfile=local.copy,'baseballdatabank-master/core/Salaries.csv'))
head(bs)
install.packages('ggplot2')
#mpg dataset
library(gglplot2)
#mpg dataset
library(ggplot2)
mpg
str(mpg)
mpg$displ
as.data.frame(midwest)
midwest<-as.data.frame(midwest)
install.packages('dplyr')
library(dplyr)
#rename(데이터프레임, 변경후컬럼이름=변경전컬럼이름)
midw
#rename(데이터프레임, 변경후컬럼이름=변경전컬럼이름)
midwest
rename(midwest,cg=category)
head(midwest)
# 1. 시험 점수 변수 만들고 출력하기
# 다섯 명의 학생이 시험을 봤습니다. 학생 다섯 명의 시험 점수를 담고 있는 변수를 만들어 출력해 보세요. 각
# 학생의 시험 점수는 다음과 같습니다.
# 80, 60, 70, 50, 90
test<-data.frame()
fix(test)
test
# 2. 전체 평균 구하기
# 앞 문제에서 만든 변수를 이용해서 이 학생들의 전체 평균 점수를 구해보세요.
rowMeans(test)
#
# 3. 전체 평균 변수 만들고 출력하기
# 전체 평균 점수를 담고 있는 새 변수를 만들어 출력해 보세요. 앞 문제를 풀 때 사용한 코드를 응용하면
# 됩니다.
test['평균']=rowMeans(test)
test
제품<-c('사과','딸기','수박박')
가격<-c(1800,1500,3000)
판매량<-c(24,38,13)
data.frame(제품,가격,판매량)
data.frame(가격,판매량,row.name=F)
data.frame(가격,판매량,row.names=F)
data.frame(가격,판매량,row.names=제품품)
data.frame(가격,판매량,row.names=제품)
fruite<-data.frame(가격,판매량,row.names=제품)
# 5. 앞에서 만든 데이터 프레임을 이용해서 과일 가격 평균, 판매량 평균을 구해보세요
colMeans(fruite)
fruite
# 5. 앞에서 만든 데이터 프레임을 이용해서 과일 가격 평균, 판매량 평균을 구해보세요
colMeans(fruite)
# 6. mpg 데이터의 변수명은 긴 단어를 짧게 줄인 축약어로 되어있습니다.
# cty 변수는 도시 연비, hwy 변수는고속도로 연비를 의미합니다.
# 변수명을 이해하기 쉬운 단어로 바꾸려고 합니다.
# mpg 데이터를 이용해서 아래 문제를 해결해 보세요.
# • Q1. ggplot2 패키지의 mpg 데이터를 사용할 수 있도록 불러온 뒤 복사본을 만드세요.
library(ggplot2)
head(mpg)
mpg_dup=mpg
mpg_dup<-data.frame(mpg)
mpg_dup
names(mpg_dup)
library(dplyr)
rename(mpg_dup,cty,city)
rename(mpg_dup,cty=city)
mpg_dup
rename(mpg_dup,cty=city)
rename(mpg_dup,city=cty)
names(mpg_dup)
rename(mpg_dup,city=cty)
names(mpg_dup)
midwest<-as.data.frame(midwest)
#rename(데이터프레임, 변경후컬럼이름=변경전컬럼이름)
midwest
names(midwest)
rename(midwest,cg=category)
names(midwest)
midwest<-as.data.frame(midwest)
names(midwest)
head(midwest)
head(mpg_dup)
?rename
rename(mpg_dup,city=cty)
head(mpg_dup)
rename(mpg_dup,highway=hwy)
head(mpg_dup)
mpg_dup<-rename(mpg_dup,city=cty)
mpg_dup<-rename(mpg_dup,highway=hwy)
head(mpg_dup)
names(mpg_dup)
# • Q3 자동차 배기량에 따라 고속도로 연비가 다른지 알아보자
# - displ(배기량)이 4 이하인 자동차와 5 이상인 자동차 중 어떤 자동차의 hwy(연비)가 평균적으로 높은가?
mpg_dup[mpg_dup$displ>=4,'highway']
mpg_dup[mpg_dup$displ>=5,'highway']
# • Q3 자동차 배기량에 따라 고속도로 연비가 다른지 알아보자
# - displ(배기량)이 4 이하인 자동차와 5 이상인 자동차 중 어떤 자동차의 hwy(연비)가 평균적으로 높은가?
mean(mpg_dup[mpg_dup$displ<=4,'highway'])
mean(mpg_dup[mpg_dup$displ>=5,'highway'])
# • Q3 자동차 배기량에 따라 고속도로 연비가 다른지 알아보자
# - displ(배기량)이 4 이하인 자동차와 5 이상인 자동차 중 어떤 자동차의 hwy(연비)가 평균적으로 높은가?
under4hwy<-mean(mpg_dup[mpg_dup$displ<=4,'highway'])
over5hwymean(mpg_dup[mpg_dup$displ>=5,'highway'])
# • Q3 자동차 배기량에 따라 고속도로 연비가 다른지 알아보자
# - displ(배기량)이 4 이하인 자동차와 5 이상인 자동차 중 어떤 자동차의 hwy(연비)가 평균적으로 높은가?
under4hwy<-mean(mpg_dup[mpg_dup$displ<=4,'highway'])
over5hwy<-mean(mpg_dup[mpg_dup$displ>=5,'highway'])
max(under4hwy,over5hwy)
#   • Q5. 자동차 제조 회사에 따라 도시 연비가 다른지 알아보자.
# -"audi"와 "toyota" 중 어느 manufacturer의 cty가 평균적으로 높은지 알아 보자.
str(mpg_dup)
mpg_dup$manufacturer<-as.factor(mpg_dup$manufacturer)
str(mpg_dup)
tail(mpg_dup)
str(mpg_dup)
unique(mpg_dup$manufacturer)
levels(mpg_dup$manufacturer)
manf<-levels(mpg_dup$manufacturer)
mpg_dup$city[mpg$manufacturer=='audi']
mpg_dup$city[mpg$manufacturer=='toyota']
audicty<-mean(mpg_dup$city[mpg$manufacturer=='audi'])
toyotacty<-mean(mpg_dup$city[mpg$manufacturer=='toyota'])
max(audicty,toyotacty)
c(audicty,toyotacty)
list(audicty,toyotacty)
c
c(audicty,toyotacty)
# • Q6. 자동차 종류에 따라 도시 연비가 다른지 알아보자.
# - class가 "suv"인 자동차와 "compact"인 자동차 중 어떤 자동차의 cty가 더 높은지 알아보자.
str(mpg_dup)
unique(mpg_dup$class)
mpgClass<-unique(mpg_dup$class)
mpg_dup$cty[mpg_dup$class=='compact']
mpg_dup$city[mpg_dup$class=='compact']
mpg_dup$city[mpg_dup$class=='suv']
compactCty<-mean(mpg_dup$city[mpg_dup$class=='compact'])
suvCty<-mean(mpg_dup$city[mpg_dup$class=='suv'])
c(compactCty,suvCty)
midwest
str(midwest)
# • 문제 2. poptotal(전체 인구)을 total 로, popasian(아시아 인구)을 asian 으로 변수명을 수정하세요.
rename(midwest,total=poptotal)
midwest<-rename(midwest,asian=popasian)
head(midwest)
str(midwest)
# • 문제 2. poptotal(전체 인구)을 total 로, popasian(아시아 인구)을 asian 으로 변수명을 수정하세요.
midwest<-rename(midwest,total=poptotal)
head(midwest)
str(midwest)
size<-c()
midwest$asian
str(midwest)
head(midwest)
str(midwest)
# • 문제 3. 아시아 인구 백분율 전체 평균을 구하고, 평균을 초과하면 "large", 그 외에는 "small"을 부여하는
# 파생변수를 만들어 보세요
prop<-midwest$asian/midwest$total
prop
# • 문제 3. 아시아 인구 백분율 전체 평균을 구하고, 평균을 초과하면 "large", 그 외에는 "small"을 부여하는
# 파생변수를 만들어 보세요
prop<-mean(midwest$asian/midwest$total)
prop
# • 문제 3. 아시아 인구 백분율 전체 평균을 구하고, 평균을 초과하면 "large", 그 외에는 "small"을 부여하는
# 파생변수를 만들어 보세요
prop<-midwest$asian/midwest$total
mean(prop)
meanProp<-mean(prop)
prop>meanProp
midwest$size<-c('large')
midwest$size
midwest$size[prop<=meanProp]<-'small'
midwest$size
# 8. 햄릿 데이터 파일을 읽은 후 다음 작업을 진행하시오.
read.table('data/Hamlet.txt')
# read.table(), txt파일
# read.table은 디폴트가 헤더가 F
p<-read.table('data/product.txt')
p
#연결자 설정하기 sep=''옵션
read.table('data/product-colon.txt',sep=':',header=T)
# read.table(), txt파일
# read.table은 디폴트가 헤더가 F
p<-read.table('data/product.txt')
p
# 8. 햄릿 데이터 파일을 읽은 후 다음 작업을 진행하시오.
read.table('data/Hamlet.txt')
?read.table
# 8. 햄릿 데이터 파일을 읽은 후 다음 작업을 진행하시오.
read.table('data/Hamlet.txt',comment.char = '')
# 8. 햄릿 데이터 파일을 읽은 후 다음 작업을 진행하시오.
read.table('data/Hamlet.txt',comment.char = '')
# 8. 햄릿 데이터 파일을 읽은 후 다음 작업을 진행하시오.
read.table('data/Hamlet.txt',comment.char = '',sep='')
# 8. 햄릿 데이터 파일을 읽은 후 다음 작업을 진행하시오.
read.table('data/Hamlet.txt',comment.char = '',sep=' ')
# 8. 햄릿 데이터 파일을 읽은 후 다음 작업을 진행하시오.
read.table('data/Hamlet.txt',comment.char = '',sep=' ',header=F)
# 8. 햄릿 데이터 파일을 읽은 후 다음 작업을 진행하시오.
read.table('data/Hamlet.txt',comment.char = '',sep=' ',header=T)
# 8. 햄릿 데이터 파일을 읽은 후 다음 작업을 진행하시오.
read.table('data/Hamlet.txt',comment.char = '',sep='\n',header=F)
# 8. 햄릿 데이터 파일을 읽은 후 다음 작업을 진행하시오.
read.table('data/Hamlet.txt',sep='\n',header=F)
# 8. 햄릿 데이터 파일을 읽은 후 다음 작업을 진행하시오.
read.table('data/Hamlet.txt')
# 8. 햄릿 데이터 파일을 읽은 후 다음 작업을 진행하시오.
haml<-read.table('data/Hamlet.txt')
# 8. 햄릿 데이터 파일을 읽은 후 다음 작업을 진행하시오.
haml<-read.table('data/Hamlet.txt',sep='\n')
haml
str(haml)
# 8. 햄릿 데이터 파일을 읽은 후 다음 작업을 진행하시오.
haml<-read.table('data/Hamlet.txt',sep='\n',header=F)
haml
# 8. 햄릿 데이터 파일을 읽은 후 다음 작업을 진행하시오.
haml<-read.table('data/Hamlet.txt',sep='\t',header=F)
haml
# 8. 햄릿 데이터 파일을 읽은 후 다음 작업을 진행하시오.
haml<-read.table('data/Hamlet.txt',fill=T)
haml
# 8. 햄릿 데이터 파일을 읽은 후 다음 작업을 진행하시오.
haml<-read.table('data/Hamlet.txt',fill=T,sep='\n')
haml
# 8. 햄릿 데이터 파일을 읽은 후 다음 작업을 진행하시오.
haml<-readLines('data/Hamlet.txt')
haml
str(haml)
haml[1]
# • 문제 1. ******로 시작하고 ******로 끝나는 문자열 추출
grep('^[*]{7}.*[*]{7}$',haml)
# • 문제 1. ******로 시작하고 ******로 끝나는 문자열 추출
grep('^[*].*[*]$',haml)
# • 문제 1. ******로 시작하고 ******로 끝나는 문자열 추출
grep('^[*].*[*]$',haml,value=T)
# • 문제 1. ******로 시작하고 ******로 끝나는 문자열 추출
grep('^[*]{6}.+[*]$',haml,value=T)
# • 문제 1. ******로 시작하고 ******로 끝나는 문자열 추출
grep('^[*]{6}.+[*]{6}$',haml,value=T)
# • 문제 2. 대문자로 시작되는 단어들만 추출 -> 단어별 빈도수 출력
grep('^[[:upper:]]',haml,value=T)
# • 문제 2. 대문자로 시작되는 단어들만 추출 -> 단어별 빈도수 출력
class(grep('^[[:upper:]]',haml,value=T))
# • 문제 2. 대문자로 시작되는 단어들만 추출 -> 단어별 빈도수 출력
str(grep('^[[:upper:]]',haml,value=T))
# • 문제 2. 대문자로 시작되는 단어들만 추출 -> 단어별 빈도수 출력
?strsplit
strsplit(grep('^[[:upper:]]',haml,value=T),' ')
?lapply
lapply(strsplit(grep('^[[:upper:]]',haml,value=T),' '),grep,'^[[:upper:]]',value=T)
lapply(strsplit(grep('^[[:upper:]]',haml,value=T),' '),unlist)
unlist(strsplit(grep('^[[:upper:]]',haml,value=T),' '))
unlist(strsplit(haml,' '))
unlist(strsplit(haml,' '))
haml1<-unlist(strsplit(haml,' '))
str(haml1)
grep('^[[:upper:]]',haml1,value=T)
# [[:alnum:]], \\w 알파벳, 숫자
# [[:alpha:]] 알파벳
# [[:digit:]] 숫자
# [[:punct:]] 문장부호, 특수문자
# [[:space:]] 공백
words2<-c("12 Dec", "OK", "http://", "<TITLE>Time?</TITLE>","12345", "Hi there")
grep('[[:alnum:]]',words2,value = T)
grep('^[[:upper:]],haml1,value=T)
grep('^[[:upper:]][[:alpha:]]*$,haml1,value=T)
grep('^[[:upper:]],haml1,value=T)
grep('^[[:upper:]][[:alpha:]]*$',haml1,value=T)
?lapply
# • 문제 3. 대괄호([ 또는 ])로 묶여있는 문자열 출력
# • 문제 4. 모든 단어를 소문자로 변환 -> 가장 빈도수가 높은 단어 50개 출력
# • 문제 5. Ham. ->Hamlet. 으로 치환
# • 문제 6. Scene 으로 시작되는 문자열 출력
#
# 9. 2021년 2월 27일부터 7일간 월, 일, 요일을 출력
# "토-0227" "일-0228" ...
grep('^[[:upper:]][[:alpha:]]*$',haml1,value=T)
length(grep('^[[:upper:]][[:alpha:]]*$',haml1,value=T))
length(grep('^[[:upper:]]',haml1,value=T))
length(grep('^[[:upper:]][[:alpha:]]*$',haml1,value=T))
Uppers<-grep('^[[:upper:]]',haml1,value=T)
gsub('[^[:alpha:]]',replacement = '',Uppers)
str(Uppers)
str(gsub('[^[:alpha:]]',replacement = '',Uppers))
Uppers<-gsub('[^[:alpha:]]',replacement = '',Uppers)
table(Uppers)
max(table(Uppers))
# • 문제 3. 대괄호([ 또는 ])로 묶여있는 문자열 출력
charr<-grep("^[[]",haml1,value=T)
charr
# • 문제 3. 대괄호([ 또는 ])로 묶여있는 문자열 출력
charr<-grep("^[[].*[]]$",haml1,value=T)
charr
# • 문제 4. 모든 단어를 소문자로 변환 -> 가장 빈도수가 높은 단어 50개 출력
lowers<-tolower(haml1)
lowers
# • 문제 3. 대괄호([ 또는 ])로 묶여있는 문자열 출력
charr<-grep("[[].*[]]",haml,value=T)
charr
gsup('.*[[]',replacement='',charr)
gsub('.*[[]',replacement='',charr)
gsub('.*[[]|[]].*',replacement='',charr)
lowers
gsub('[^[:alpha:]]',replacement = '',lowers)
lowers<-gsub('[^[:alpha:]]',replacement = '',lowers)[lowers!='']
lowers
lowers<-gsub('[^[:alpha:]]',replacement = '',lowers)
# • 문제 4. 모든 단어를 소문자로 변환 -> 가장 빈도수가 높은 단어 50개 출력
lowers<-tolower(haml1)
lowers<-gsub('[^[:alpha:]]',replacement = '',lowers)
table(lowers)
c(table(lowers))
order(c(table(lowers)))
sort(c(table(lowers)))
sort(c(table(lowers)),decreasing = T)
sort(c(table(lowers)),decreasing = T)[1:10]
sort(c(table(lowers)),decreasing = T)[1:10][-3]
lowers<-grep('[[:alpha:]]',gsub('[^[:alpha:]]',replacement = '',lowers))
sort(c(table(lowers)),decreasing = T)
lowers<-grep('[[:alpha:]]',gsub('[^[:alpha:]]',replacement = '',lowers),value = T)
sort(c(table(lowers)),decreasing = T)[1:10]
lowers<-gsub('[^[:alpha:]]',replacement = '',lowers)
lowers
# • 문제 4. 모든 단어를 소문자로 변환 -> 가장 빈도수가 높은 단어 50개 출력
lowers<-tolower(haml1)
lowers<-gsub('[^[:alpha:]]',replacement = '',lowers)
lowers
lowers[lowers==""]
lowers[lowers!=""]
lowers<-lowers[lowers!=""]
sort(c(table(lowers)),decreasing = T)[1:9]
sort(c(table(lowers)),decreasing = T)[1:50]
# • 문제 5. Ham. ->Hamlet. 으로 치환
gsub('Ham[.]',replacement = 'Hamlet.',haml1)
# • 문제 5. Ham. ->Hamlet. 으로 치환
repla<-gsub('Ham[.]',replacement = 'Hamlet.',haml1)
grep('Ham[.]',repla,value = T)
grep('Hamlet[.]',repla,value = T)
# • 문제 6. Scene 으로 시작되는 문자열 출력
grep('^(Scene)',haml,value = T)
Sys.date()
Sys.Date()
today<-Sys.Date()
today+1
seq(today+1,by=1,length.out=7)
date7<-seq(today+1,by=1,length.out=7)
weekdays(date7)
month(date7)
Month(date7)
months(date7)
format(date7,format='%d일일')
format(date7,format='%d일')
weeks<-weekdays(date7)
Monthhs<-months(date7)
dayys<-format(date7,format='%d일')
data.frame(date7,weeks,Monthhs,dayys)
